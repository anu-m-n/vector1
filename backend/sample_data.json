{
  "nodes": [
    {
      "title": "Transformer (ML)",
      "text": "Transformer is a deep learning model architecture introduced in 2017 for sequence modeling and transduction tasks.",
      "metadata": {
        "topic": "ML"
      }
    },
    {
      "title": "Attention Mechanism",
      "text": "Attention allows models to focus on different parts of the input sequence when producing each element of the output sequence.",
      "metadata": {
        "topic": "ML"
      }
    },
    {
      "title": "BERT",
      "text": "BERT is a transformer-based model pre-trained on large corpora for language understanding.",
      "metadata": {
        "topic": "NLP"
      }
    },
    {
      "title": "GPT",
      "text": "GPT family are large transformer-based language models focusing on generative tasks.",
      "metadata": {
        "topic": "NLP"
      }
    },
    {
      "title": "Sentence Embeddings",
      "text": "Sentence embeddings convert text into fixed-size vectors capturing semantic meaning.",
      "metadata": {
        "topic": "ML"
      }
    },
    {
      "title": "Cosine Similarity",
      "text": "Cosine similarity measures the cosine of the angle between two vectors in a multidimensional space.",
      "metadata": {
        "topic": "Math"
      }
    },
    {
      "title": "Graph Databases",
      "text": "Graph databases store data in nodes and edges optimized for relationship queries.",
      "metadata": {
        "topic": "DB"
      }
    },
    {
      "title": "Knowledge Graph",
      "text": "Knowledge graphs represent entities and their relationships for semantic queries.",
      "metadata": {
        "topic": "AI"
      }
    },
    {
      "title": "RAG (Retrieval-Augmented Generation)",
      "text": "RAG systems combine retrieval and generation to produce grounded responses.",
      "metadata": {
        "topic": "AI"
      }
    },
    {
      "title": "SQLite",
      "text": "SQLite is a lightweight file-based database engine used for local persistence.",
      "metadata": {
        "topic": "DB"
      }
    },
    {
      "title": "Vector Search",
      "text": "Vector search finds items by semantic similarity using embeddings and distance metrics.",
      "metadata": {
        "topic": "Search"
      }
    },
    {
      "title": "Graph Traversal",
      "text": "Graph traversal algorithms like BFS and DFS explore nodes and edges systematically.",
      "metadata": {
        "topic": "Algorithms"
      }
    },
    {
      "title": "Hybrid Retrieval",
      "text": "Hybrid retrieval combines vector similarity with graph-based reasoning to improve relevance.",
      "metadata": {
        "topic": "AI"
      }
    },
    {
      "title": "Node Embeddings",
      "text": "Node embeddings are vector representations of graph nodes enabling ML on graphs.",
      "metadata": {
        "topic": "ML"
      }
    },
    {
      "title": "Knowledge Assistant",
      "text": "A knowledge assistant uses retrieval to ground its answers on factual documents.",
      "metadata": {
        "topic": "Application"
      }
    },
    {
      "title": "Multi-hop QA",
      "text": "Multi-hop QA requires retrieving and reasoning across multiple documents or nodes.",
      "metadata": {
        "topic": "NLP"
      }
    },
    {
      "title": "Entity Linking",
      "text": "Entity linking connects mentions in text to canonical entities in a knowledge base.",
      "metadata": {
        "topic": "NLP"
      }
    },
    {
      "title": "Semantic Similarity",
      "text": "Semantic similarity quantifies how much two texts mean the same thing.",
      "metadata": {
        "topic": "NLP"
      }
    },
    {
      "title": "Embedding Models",
      "text": "Embedding models map text to dense vectors; popular sources include transformer models.",
      "metadata": {
        "topic": "ML"
      }
    },
    {
      "title": "Evaluation Metrics",
      "text": "Evaluation uses precision, recall, and qualitative examples to compare retrieval modes.",
      "metadata": {
        "topic": "ML"
      }
    }
  ],
  "edges": [
    {
      "source": 1,
      "target": 2,
      "type": "related",
      "weight": 1.0
    },
    {
      "source": 2,
      "target": 3,
      "type": "example",
      "weight": 1.0
    },
    {
      "source": 2,
      "target": 4,
      "type": "example",
      "weight": 1.0
    },
    {
      "source": 5,
      "target": 11,
      "type": "used_in",
      "weight": 1.0
    },
    {
      "source": 11,
      "target": 13,
      "type": "part_of",
      "weight": 1.0
    },
    {
      "source": 7,
      "target": 8,
      "type": "instance",
      "weight": 1.0
    },
    {
      "source": 8,
      "target": 15,
      "type": "used_by",
      "weight": 1.0
    },
    {
      "source": 9,
      "target": 4,
      "type": "uses",
      "weight": 1.0
    },
    {
      "source": 12,
      "target": 14,
      "type": "related",
      "weight": 1.0
    },
    {
      "source": 16,
      "target": 15,
      "type": "requires",
      "weight": 1.0
    },
    {
      "source": 18,
      "target": 5,
      "type": "describes",
      "weight": 1.0
    },
    {
      "source": 19,
      "target": 11,
      "type": "about",
      "weight": 1.0
    }
  ]
}